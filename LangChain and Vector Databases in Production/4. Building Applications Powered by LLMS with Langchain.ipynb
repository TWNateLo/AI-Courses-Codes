{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Applications Powered by LLMs with LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain is designed to assist developers in building end-to-end applications using language models. It offers an array of tools, components, and interfaces that simplify the process of creating applications powered by large language models and chat models. LangChain streamlines managing interactions with LLMs, chaining together multiple components, and integrating additional resources, such as APIs and databases. Having gained a foundational understanding of the library in previous lesson, let's now explore various examples of utilizing prompts to accomplish multiple tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt use case:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A key feature of LangChain is its support for prompts, which encompasses prompt management, prompt optimization, and a generic interface for all LLMs. The framework also provides common utilities for working with LLMs.\n",
    "\n",
    "ChatPromptTemplate is used to create a structured conversation with the AI model, making it easier to manage the flow and content of the conversation. In LangChain, message prompt templates are used to construct and work with prompts, allowing us to exploit the underlying chat model's potential fully.\n",
    "\n",
    "System and Human prompts differ in their roles and purposes when interacting with chat models. SystemMessagePromptTemplate provides initial instructions, context, or data for the AI model, while HumanMessagePromptTemplate are messages from the user that the AI model responds to.\n",
    "\n",
    "To illustrate it, let’s create a chat-based assistant that helps users find information about movies. Ensure your OpenAI key is stored in environment variables using the “OPENAI_API_KEY” name. Remember to install the required packages with the following command: pip install langchain==0.1.4 deeplake openai==1.10.0 tiktoken pypdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Inception\" is a 2010 science fiction action film written and directed by Christopher Nolan. The film stars Leonardo DiCaprio as a professional thief who steals information by entering the subconscious minds of his targets through their dreams. The ensemble cast also includes Joseph Gordon-Levitt, Ellen Page, Tom Hardy, Ken Watanabe, and Marion Cotillard.\n",
      "\n",
      "The movie explores the concept of dream sharing and features stunning visual effects and mind-bending action sequences. \"Inception\" received critical acclaim for its originality, storytelling, and visual effects, and was a commercial success at the box office.\n",
      "\n",
      "If you have any specific questions or need more information about \"Inception,\" feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "# Before executing the following code, make sure to have\n",
    "# your OpenAI key saved in the “OPENAI_API_KEY” environment variable.\n",
    "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "template = \"You are an assistant that helps users find information about movies.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "human_template = \"Find information about the movie {movie_title}.\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "response = chat(chat_prompt.format_prompt(movie_title=\"Inception\").to_messages())\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the to_messages object in LangChain allows you to convert the formatted value of a chat prompt template into a list of message objects. This is useful when working with chat models, as it provides a structured way to manage the conversation and ensures that the chat model can understand the context and roles of the messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarization chain example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain prompts can be found in various use cases, such as summarization or question-answering chains. For example, when creating a summarization chain, LangChain enables interaction with an external data source to fetch data for use in the generation step. This could involve summarizing a lengthy piece of text or answering questions using specific data sources.\n",
    "\n",
    "The following code will initialize the language model using OpenAI class with a temperature of 0 - because we want deterministic output.  The load_summarize_chain function accepts an instance of the language model and returns a pre-built summarization chain. Lastly, the PyPDFLoader class is responsible for loading PDF files and converting them into a format suitable for processing by LangChain. \n",
    "\n",
    "It is important to note that you need to install the pypdf package to run the following code. Although it is highly recommended to install the latest versions of this package, the codes have been tested on version 3.10.0. Please refer to course introduction lesson for more information on installing packages. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "Have to use the different model (non instruct/chat model) to process the summarization task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='THE ONE     PAGE LINUX MANUALA summary of useful Linux commands\\nVersion 3.0 May 1999 squadron@powerup.com.au\\nStarting & Stopping\\nshutdown -h now Shutdown the system now and do not\\nreboot\\nhalt Stop all processes - same as above\\nshutdown -r 5 Shutdown the system in 5 minutes and\\nreboot\\nshutdown -r now Shutdown the system now and reboot\\nreboot Stop all processes and then reboot - same\\nas above\\nstartx Start the X system\\nAccessing & mounting file systems\\nmount -t iso9660 /dev/cdrom\\n/mnt/cdromMount the device cdrom\\nand call it cdrom under the\\n/mnt directory\\nmount -t msdos /dev/hdd\\n/mnt/ddriveMount hard disk “d” as a\\nmsdos file system and call\\nit ddrive under the /mnt\\ndirectory\\nmount -t vfat /dev/hda1\\n/mnt/cdriveMount hard disk “a” as a\\nVFAT file system and call it\\ncdrive under the /mnt\\ndirectory\\numount /mnt/cdrom Unmount the cdrom\\nFinding files and text within files\\nfind / -name  fname Starting with the root directory, look\\nfor the file called fname\\nfind / -name ”*fname* ” Starting with the root directory, look\\nfor the file containing the string fname\\nlocate missingfilename Find a file called missingfilename\\nusing the locate command - this\\nassumes you have already used the\\ncommand updatedb (see next)\\nupdatedb Create or update the database of files\\non all file systems attached to the linux\\nroot directory\\nwhich missingfilename Show the subdirectory containing the\\nexecutable file  called missingfilename\\ngrep textstringtofind\\n/dirStarting with the directory called dir ,\\nlook for and list all files containing\\ntextstringtofind\\nThe X Window System\\nxvidtune Run the X graphics tuning utility\\nXF86Setup Run the X configuration menu with\\nautomatic probing of graphics cards\\nXconfigurator Run another X configuration menu with\\nautomatic probing of graphics cards\\nxf86config Run a text based X configuration menu\\nMoving, copying, deleting & viewing files\\nls -l List files in current directory using\\nlong format\\nls -F List files in current directory and\\nindicate the file type\\nls -laC List all files in current directory in\\nlong format and display in columnsrm name Remove a file or directory called\\nname\\nrm -rf name Kill off an entire directory and all it’s\\nincludes files and subdirectories\\ncp filename\\n/home/dirnameCopy the file called filename to the\\n/home/dirname directory\\nmv filename\\n/home/dirnameMove the file called filename to the\\n/home/dirname directory\\ncat filetoview Display the file called filetoview\\nman -k keyword Display man pages containing\\nkeyword\\nmore filetoview Display the file called filetoview one\\npage at a time, proceed to next page\\nusing the spacebar\\nhead filetoview Display the first 10 lines of the file\\ncalled filetoview\\nhead -20 filetoview Display the first 20 lines of the file\\ncalled filetoview\\ntail filetoview Display the last 10 lines of the file\\ncalled filetoview\\ntail -20 filetoview Display the last 20 lines of the file\\ncalled filetoview\\nInstalling software for Linux\\nrpm -ihv name.rpm Install the rpm package called name\\nrpm -Uhv name.rpm Upgrade the rpm package called\\nname\\nrpm -e package Delete the rpm package called\\npackage\\nrpm -l package List the files in the package called\\npackage\\nrpm -ql package List the files and state the installed\\nversion of the package called\\npackage\\nrpm -i --force package Reinstall the rpm package called\\nname having deleted parts of it (not\\ndeleting using rpm -e)\\ntar -zxvf archive.tar.gz or\\ntar -zxvf archive.tgzDecompress the files contained in\\nthe zipped and tarred archive called\\narchive\\n./configure Execute the script preparing the\\ninstalled files for compiling\\nUser Administration\\nadduser accountname Create a new user call accountname\\npasswd accountname Give accountname a new password\\nsu Log in as superuser from current login\\nexit Stop being superuser and revert to\\nnormal user\\nLittle known tips and tricks\\nifconfig List ip addresses for all devices on\\nthe machine\\napropos subject List manual pages for subject\\nusermount Executes graphical application for\\nmounting and unmounting file\\nsystems', metadata={'source': 'The One Page Linux Manual.pdf', 'page': 0}), Document(page_content='/sbin/e2fsck hda5 Execute the filesystem check utility\\non partition hda5\\nfdformat /dev/fd0H1440 Format the floppy disk in device fd0\\ntar -cMf /dev/fd0 Backup the contents of the current\\ndirectory and subdirectories to\\nmultiple floppy disks\\ntail -f /var/log/messages Display the last 10 lines of the system\\nlog.\\ncat /var/log/dmesg Display the file containing the boot\\ntime messages - useful for locating\\nproblems. Alternatively, use the\\ndmesg  command.\\n* wildcard - represents everything. eg.\\ncp from/* to  will copy all files in the\\nfrom directory to the to directory\\n? Single character wildcard. eg.\\ncp config.? /configs will copy all files\\nbeginning with the name config. in\\nthe current directory to the directory\\nnamed configs.\\n[xyz] Choice of character wildcards. eg.\\nls [xyz]* will list all files in the current\\ndirectory starting with the letter x, y,\\nor z.\\nlinux single At the lilo prompt, start in single user\\nmode. This is useful if you have\\nforgotten your password. Boot in\\nsingle user mode, then run the\\npasswd  command.\\nps List current processes\\nkill 123 Kill a specific process eg. kill 123\\nConfiguration files and what they do\\n/etc/profile System wide environment variables for\\nall users.\\n/etc/fstab List of devices and their associated mount\\npoints. Edit this file to add cdroms, DOS\\npartitions and floppy drives at startup.\\n/etc/motd Message of the day broadcast to all users\\nat login.\\netc/rc.d/rc.local Bash script that is executed at the end of\\nlogin process. Similar to autoexec.bat in\\nDOS.\\n/etc/HOSTNAME Conatins full hostname including domain.\\n/etc/cron.* There are 4 directories that automatically\\nexecute all scripts within the directory at\\nintervals of hour, day, week or month.\\n/etc/hosts A list of all know host names and IP\\naddresses on the machine.\\n/etc/httpd/conf Paramters for the Apache web server\\n/etc/inittab Specifies the run level that the machine\\nshould boot into.\\n/etc/resolv.conf Defines IP addresses of DNS servers.\\n/etc/smb.conf Config file for the SAMBA server. Allows\\nfile and print sharing with Microsoft\\nclients.\\n/etc/X11/XF86Confi\\ngConfig file for X -Windows.\\n~/.xinitrc Defines the windows manager loaded by\\nX. ~ refers to user’s home directory.File permissions\\nIf the command ls -l is given, a long list of file names is\\ndisplayed. The first column in this list details the permissions\\napplying to the file. If a permission is missing for a owner,\\ngroup of other, it is represented by - eg.  drwxr -x—x\\nRead = 4\\nWrite = 2\\nExecute = 1File permissions are altered by giving the\\nchmod command and the appropriate\\noctal code for each user type. eg\\nchmod 7 6 4 filename will make the file\\ncalled filename R+W+X for the owner,\\nR+W for the group and R for others.\\nchmod 7 5 5 Full permission for the owner, read and\\nexecute access for the group and others.\\nchmod +x filename Make the file called filename executable\\nto all users.\\nX Shortcuts - (mainly for Redhat)\\nControl|Alt  + or - Increase or decrease the screen\\nresolution. eg. from 640x480 to\\n800x600\\nAlt | escape Display list of active windows\\nShift|Control F8 Resize the selected window\\nRight click on desktop\\nbackgroundDisplay menu\\nShift|Control Altr Refresh the screen\\nShift|Control Altx Start an xterm session\\nPrinting\\n/etc/rc.d/init.d/lpd start Start the print daemon\\n/etc/rc.d/init.d/lpd stop Stop the print daemon\\n/etc/rc.d/init.d/lpd\\nstatusDisplay status of the print daemon\\nlpq Display jobs in print queue\\nlprm Remove jobs from queue\\nlpr Print a file\\nlpc Printer control tool\\nman subject | lpr Print the manual page called subject\\nas plain text\\nman -t subject | lpr Print the manual page called subject\\nas Postscript output\\nprinttool Start X printer setup interface~/.Xdefaults Define configuration for some X -\\napplications. ~ refers to user’s home\\ndirectory.\\nGet your own Official Linux Pocket Protector - includes\\nhandy command summary. Visit:\\nwww.powerup.com.au/~squadron', metadata={'source': 'The One Page Linux Manual.pdf', 'page': 1})]\n",
      "The One Page Linux Manual is a summary of useful Linux commands. It includes commands for starting and stopping the system, accessing and mounting file systems, finding files and text within files, using the X Window System, moving, copying, deleting, and viewing files, installing software, user administration, and various tips and tricks. It also provides information on configuration files and file permissions. The manual also includes shortcuts for Redhat users and commands for printing.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from langchain import OpenAI, PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Initialize language model\n",
    "#llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0)\n",
    "# Switching to non instruct (non chat model) can work, but it replies nothing provided for summarizing...\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo-16k\", temperature=0)\n",
    "\n",
    "\n",
    "# Load the summarization chain\n",
    "summarize_chain = load_summarize_chain(llm)\n",
    "\n",
    "# Load the document using PyPDFLoader\n",
    "document_loader = PyPDFLoader(file_path=\"The One Page Linux Manual.pdf\")\n",
    "document = document_loader.load()\n",
    "\n",
    "print(document)\n",
    "\n",
    "# Summarize the document\n",
    "summary = summarize_chain(document)\n",
    "print(summary['output_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This document provides a summary of useful Linux commands for starting and stopping, accessing and mounting file systems, finding files and text within files, the X Window System, moving, copying, deleting and viewing files, installing software, user administration, little known tips and tricks, configuration files and what they do, file permissions, X shortcuts, printing, and a link to an official Linux pocket protector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output. The output above is based on the “The One Page Linux Manual” PDF file accessible at this URL(https://www.cheat-sheets.org/saved-copy/The%20One%20Page%20Linux%20Manual.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the code uses the default summarization chain provided by the load_summarize_chain function. However, you can customize the summarization process by providing prompt templates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s recap:  OpenAI is initialized with a temperature of 0 for focused and deterministic language model generation. The load_summarize_chain function loads a summarization chain, and PyPDFLoader fetches PDF data, which is loaded as a string input for the summarization chain, generating a summary of the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another good summarization tutorial for LangChain:\n",
    "\n",
    "There are 3 main ways to implement the summarization process, depending on the task type.\n",
    "\n",
    "https://medium.com/@abonia/summarization-with-langchain-b3d83c030889"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QA chain example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use LangChain to manage prompts for asking general questions from the LLMs. These models are proficient in addressing fundamental inquiries. Nevertheless, it is crucial to remain mindful of the potential issue of hallucinations, where the models may generate non-factual information. To address this concern, we will later introduce the Retrieval chain as a means to overcome this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "prompt = PromptTemplate(template=\"Question: {question}\\nAnswer:\", input_variables=[\"question\"])\n",
    "\n",
    "#llm = OpenAI(model_name=\"gpt-3.5-turbo-instruct\", temperature=0)\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a custom prompt template by creating an instance of the PromptTemplate class. The template string contains a placeholder {question} for the input question, followed by a newline character and the \"Answer:\" label.  The input_variables argument is set to the list of available placeholders in the prompt (like a question in this case) to indicate the name of the variable that the chain will replace in the template.run() method.\n",
    "\n",
    "We then instantiate an OpenAI model named gpt-3.5-turbowith a temperature of 0. The OpenAI class is used to create the instance, and the model_name and temperature arguments are provided. Finally, we create a question-answering chain using the LLMChain class. \n",
    "\n",
    "The class constructor takes two arguments: llm, which is the instantiated OpenAI model, and prompt, which is the custom prompt template we defined earlier. \n",
    "\n",
    "By following these steps, we can process input questions effectively with the custom question-answering, generating appropriate answers using the OpenAI model and the custom prompt template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The meaning of life is a philosophical question that has been debated for centuries. Different people and cultures have different beliefs about the purpose and meaning of life. Some believe that the meaning of life is to seek happiness and fulfillment, others believe it is to fulfill a higher purpose or destiny, and some believe that life has no inherent meaning and it is up to each individual to create their own meaning. Ultimately, the meaning of life is a deeply personal and subjective question that each person must answer for themselves.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"what is the meaning of life?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'The meaning of life is subjective and can vary from person to person. For some, it may be to find happiness and fulfillment, while for others it may be to make a difference in the world. Ultimately, the meaning of life is up to each individual to decide.’"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example demonstrates how LangChain simplifies the integration of LLMs with custom data sources and prompt templates for question-answering applications. To build more advanced NLP applications, you can further extend this example to include other components, such as data-augmented generation, agents, or memory features.\n",
    "\n",
    "LangChain's support for chain sequences also allows developers to create more complex applications with multiple calls to LLMs or other utilities. These chains can serve various purposes: personal assistants, chatbots, querying tabular data, interacting with APIs, extraction, evaluation, and summarization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "LangChain solves the problem of easy integration with other sources of data, tools, and different LLMs by providing a comprehensive framework for managing prompts, optimizing them, and creating a universal interface for all LLMs.\n",
    "\n",
    "In the next lesson we’ll learn more about popular language models and the recent trend in chat-based language models.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
