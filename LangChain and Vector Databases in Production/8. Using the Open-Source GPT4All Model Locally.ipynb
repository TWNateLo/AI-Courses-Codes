{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Open-Source GPT4All Model Locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The course method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The LangChain Doc method (Should be easier and more efficient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: https://python.langchain.com/v0.2/docs/integrations/providers/gpt4all/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT4All\n",
    "\n",
    "To use the GPT4All wrapper, you need to provide the path to the pre-trained model file and the model's configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import GPT4All\n",
    "\n",
    "# Instantiate the model. Callbacks support token-wise streaming\n",
    "model = GPT4All(model=\"../GPT4ALL-Models/mistral-7b-openorca.gguf2.Q4_0.gguf\", n_threads=8)\n",
    "\n",
    "# Generate text\n",
    "response = model.invoke(\"Once upon a time, \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API Reference:GPT4All\n",
    "\n",
    "You can also customize the generation parameters, such as n_predict, temp, top_p, top_k, and others.\n",
    "\n",
    "To stream the model's predictions, add in a CallbackManager."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nate.lo\\anaconda3\\envs\\Python39\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `BaseLLM.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 years ago, I was in the process of moving to New York City. It was an exciting and scary time for me as it meant leaving my family and friends behind to start fresh in this big city.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'10 years ago, I was in the process of moving to New York City. It was an exciting and scary time for me as it meant leaving my family and friends behind to start fresh in this big city.\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.llms import GPT4All\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "# There are many CallbackHandlers supported, such as\n",
    "# from langchain.callbacks.streamlit import StreamlitCallbackHandler\n",
    "\n",
    "callbacks = [StreamingStdOutCallbackHandler()]\n",
    "model = GPT4All(model=\"../GPT4ALL-Models/mistral-7b-openorca.gguf2.Q4_0.gguf\", n_threads=8)\n",
    "\n",
    "# Generate text. Tokens are streamed through the callback manager.\n",
    "model(\"Once upon a time, \", callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API Reference:GPT4All | StreamingStdOutCallbackHandler | StreamlitCallbackHandler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model File\n",
    "\n",
    "You can find links to model file downloads in the https://gpt4all.io/.\n",
    "\n",
    "For a more detailed walkthrough of this, see this [notebook](https://python.langchain.com/v0.2/docs/integrations/llms/gpt4all/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Detailed Tutorials from the documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GitHub:nomic-ai/gpt4all an ecosystem of open-source chatbots trained on a massive collections of clean assistant data including code, stories and dialogue.\n",
    "\n",
    "This example goes over how to use LangChain to interact with GPT4All models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import GPT4All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain_community.llms import GPT4All\n",
    "from langchain_core.callbacks import StreamingStdOutCallbackHandler\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Question to pass to LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify Model\n",
    "\n",
    "To run locally, download a compatible ggml-formatted model.\n",
    "\n",
    "The gpt4all page has a useful Model Explorer section:\n",
    "\n",
    "- Select a model of interest\n",
    "- Download using the UI and move the .bin to the local_path (noted below)\n",
    "\n",
    "For more info, visit https://github.com/nomic-ai/gpt4all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nate.lo\\anaconda3\\envs\\Python39\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n",
      "c:\\Users\\nate.lo\\anaconda3\\envs\\Python39\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " First, we need to find out when Justin Bieber was born. He was born on March 1, 1994. Now, let's see which NFL team won the Super Bowl in that year. The answer is the San Francisco 49ers who won the Super Bowl XXIX against the San Diego Chargers.\n",
      "\n",
      "Justin Bieber was born in London, Ontario, Canada on March 1, 1994. He is a famous Canadian singer and songwriter known for his pop music. His full name is Justin Drew Bieber. He started singing at a very young age and gained popularity using the internet to showcase his talent. In 2008, he was discovered by American manager Scooter Braun who helped him sign a record deal. Since then, Bieber has released several albums and singles that have become chart-topping hits worldwide. Some of his popular songs include \"Baby,\" \"Sorry,\" and \"What Do You Mean?\"\n",
      "\n",
      "The San Francisco 49ers are an American football team based in the San Francisco Bay Area. They compete in the National Football League (NFL) as a member club of the league's National Football Conference"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' First, we need to find out when Justin Bieber was born. He was born on March 1, 1994. Now, let\\'s see which NFL team won the Super Bowl in that year. The answer is the San Francisco 49ers who won the Super Bowl XXIX against the San Diego Chargers.\\n\\nJustin Bieber was born in London, Ontario, Canada on March 1, 1994. He is a famous Canadian singer and songwriter known for his pop music. His full name is Justin Drew Bieber. He started singing at a very young age and gained popularity using the internet to showcase his talent. In 2008, he was discovered by American manager Scooter Braun who helped him sign a record deal. Since then, Bieber has released several albums and singles that have become chart-topping hits worldwide. Some of his popular songs include \"Baby,\" \"Sorry,\" and \"What Do You Mean?\"\\n\\nThe San Francisco 49ers are an American football team based in the San Francisco Bay Area. They compete in the National Football League (NFL) as a member club of the league\\'s National Football Conference'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_path = (\n",
    "    \"../GPT4ALL-Models/mistral-7b-openorca.gguf2.Q4_0.gguf\"  # replace with your desired local file path\n",
    ")\n",
    "\n",
    "\n",
    "# Callbacks support token-wise streaming\n",
    "callbacks = [StreamingStdOutCallbackHandler()]\n",
    "\n",
    "# Verbose is required to pass to the callback manager\n",
    "llm = GPT4All(model=local_path, callbacks=callbacks, verbose=True)\n",
    "\n",
    "# If you want to use a custom model add the backend parameter\n",
    "# Check https://docs.gpt4all.io/gpt4all_python.html for supported backends\n",
    "llm = GPT4All(model=local_path, backend=\"gptj\", callbacks=callbacks, verbose=True)\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "\n",
    "question = \"What NFL team won the Super Bowl in the year Justin Bieber was born?\"\n",
    "\n",
    "llm_chain.run(question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
